{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please copy and past the destination of the first folder that you want to analyze:\n",
      "Please write whether these are 'stimuli' or 'full tracks':\n",
      "Please copy and past the destination of the second folder that you want to analyze:\n",
      "Please write whether these are 'stimuli' or 'full tracks':\n",
      "Please wait around 30 seconds...\n",
      "Correlation of Attack Rates: 0.903\n",
      "Correlation of Pitch Heights: 0.68\n",
      "Correlation of Modes: 0.874\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import pearsonr\n",
    "from pyramidi import models\n",
    "\n",
    "# Import the two folders\n",
    "print(\"Please copy and past the destination of the first folder that you want to analyze:\")\n",
    "input_folder1 = input()\n",
    "print(\"Please write whether these are 'stimuli' or 'full tracks':\")\n",
    "input_type1 = input()\n",
    "print(\"Please copy and past the destination of the second folder that you want to analyze:\")\n",
    "input_folder2 = input()\n",
    "print(\"Please write whether these are 'stimuli' or 'full tracks':\")\n",
    "input_type2 = input()\n",
    "print(\"Please wait around 30 seconds...\")\n",
    "\n",
    "def detect_mode(chroma_profile):\n",
    "    \"\"\"\n",
    "    Detect the musical mode (Major/Minor) based on the chroma profile using MIRmode.\n",
    "    \n",
    "    Args:\n",
    "        chroma_profile (numpy.ndarray): The chroma profile of the audio.\n",
    "    \n",
    "    Returns:\n",
    "        str: The detected mode ('Major' or 'Minor').\n",
    "    \"\"\"\n",
    "    return models.mirmode(chroma_profile, weights=\"BellmanBudge\")\n",
    "\n",
    "def get_pitch_height_and_std(y, sr):\n",
    "    \"\"\"\n",
    "    Calculate the average pitch height (in MIDI note numbers) and its standard deviation\n",
    "    based on the audio's Constant-Q Transform (CQT).\n",
    "\n",
    "    Args:\n",
    "        y (numpy.ndarray): The audio time-series data.\n",
    "        sr (int): The sampling rate of the audio.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The weighted average pitch height and the standard deviation of pitch height.\n",
    "    \"\"\"\n",
    "    # Compute the constant-Q transform (CQT) for pitch extraction\n",
    "    cqt_pitches = np.abs(librosa.cqt(y, sr=sr, n_bins=88, bins_per_octave=12, fmin=librosa.note_to_hz('A0')))\n",
    "    \n",
    "    # Sum energy across time for each key (MIDI note)\n",
    "    key_energy = np.sum(cqt_pitches, axis=1)\n",
    "    # Get MIDI note numbers for 88 keys (A0 to C8)\n",
    "    keyboard_notes = np.arange(21, 109)\n",
    "\n",
    "    # Calculate the weighted average pitch height (in MIDI numbers)\n",
    "    average_pitch = np.sum(key_energy * keyboard_notes) / np.sum(key_energy)\n",
    "    \n",
    "    return average_pitch\n",
    "\n",
    "def remove_last_two_seconds(file_path, sampling_rate=44100):\n",
    "    \"\"\"\n",
    "    Load an audio file using both Librosa and Essentia, and remove the last two seconds.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the audio file to be loaded.\n",
    "    sampling_rate : int, optional\n",
    "        Sampling rate for loading the audio file. Default is 44100 Hz.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    librosa_audio : numpy.ndarray\n",
    "        The audio signal without the last two seconds (Librosa).\n",
    "    essentia_audio : numpy.ndarray\n",
    "        The audio signal without the last two seconds (Essentia).\n",
    "    librosa_duration : float\n",
    "        The duration (in seconds) of the trimmed audio from Librosa.\n",
    "    essentia_duration : float\n",
    "        The duration (in seconds) of the trimmed audio from Essentia.\n",
    "    \"\"\"\n",
    "    # Load the audio file with Librosa\n",
    "    y, sr = librosa.load(file_path, sr=sampling_rate)\n",
    "    \n",
    "    # Calculate the number of samples corresponding to the last 2 seconds\n",
    "    num_samples_to_remove = int(2 * sr)\n",
    "    \n",
    "    # Remove the last 2 seconds of the Librosa audio\n",
    "    librosa_audio = y[:-num_samples_to_remove] if len(y) > num_samples_to_remove else []\n",
    "\n",
    "    return librosa_audio, sr\n",
    "\n",
    "def extract_audio_features(input_folder, type):\n",
    "    \"\"\"\n",
    "    Extract various audio features from the audio files in a specified folder.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing audio files.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Contains the pitch class distributions, tempos, attack rates,\n",
    "               modes, average volumes, and average pitch heights.\n",
    "    \"\"\"\n",
    "    # Dictionaries to store extracted features\n",
    "    attack_rates = dict()\n",
    "    modes = dict()\n",
    "    average_pitch_heights = dict()\n",
    "\n",
    "    # Iterate over files in the folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.wav', '.mp3', '.flac', '.aiff')):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            match = re.search(r'(\\d{1,2})\\s*[_]*\\s*(Major|minor)', filename)\n",
    "            \n",
    "            # Extract piece number and tonality from filename\n",
    "            if match:\n",
    "                piece_number = match.group(1)\n",
    "                tonality = match.group(2)\n",
    "                piece_name = f\"{piece_number} {tonality}\"\n",
    "            else:\n",
    "                piece_name = 'Unknown'\n",
    "\n",
    "            if type == \"stimuli\":\n",
    "                # Load the audio using librosa\n",
    "                y, sr = remove_last_two_seconds(file_path)\n",
    "            else:\n",
    "                y, sr = librosa.load(file_path, sr=44100)\n",
    "\n",
    "            # Get the duration of the audio\n",
    "            duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "            # Calculate the average pitch height of the audio\n",
    "            pitch_height = get_pitch_height_and_std(y, sr)\n",
    "\n",
    "            # Detect the musical mode based on the chroma profile\n",
    "            # Extract chroma features and calculate the average chroma profile\n",
    "            chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "            avg_chroma_profile = np.mean(chroma, axis=1)\n",
    "            avg_pitch_class_distribution = list(avg_chroma_profile)\n",
    "            \n",
    "            mode = detect_mode(avg_pitch_class_distribution)\n",
    "\n",
    "            # Calculate the number of onsets and compute the attack rate\n",
    "            num_onsets = len(list(librosa.onset.onset_detect(y=y, sr=sr, units='time')))\n",
    "            attack_rate = num_onsets / duration\n",
    "            \n",
    "            # Store the extracted features in the respective dictionaries\n",
    "            attack_rates[piece_name] = attack_rate\n",
    "            average_pitch_heights[piece_name] = pitch_height\n",
    "            modes[piece_name] = mode\n",
    "\n",
    "    return attack_rates, modes, average_pitch_heights\n",
    "\n",
    "def compute_dict_correlation(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Compute the Pearson correlation between values of two dictionaries for their common keys.\n",
    "    \n",
    "    Args:\n",
    "        dict1 (dict): The first dictionary.\n",
    "        dict2 (dict): The second dictionary.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Pearson correlation coefficient and p-value.\n",
    "    \"\"\"\n",
    "    common_keys = set(dict1.keys()).intersection(dict2.keys())\n",
    "    values1 = [dict1[key] for key in common_keys]\n",
    "    values2 = [dict2[key] for key in common_keys]\n",
    "    \n",
    "    # Calculate and return the Pearson correlation\n",
    "    return pearsonr(values1, values2)\n",
    "\n",
    "# Extract features from both input folders\n",
    "ar1, modes1, average_pitch_heights1 = extract_audio_features(input_folder1, input_type1)\n",
    "ar2, modes2, average_pitch_heights2 = extract_audio_features(input_folder2, input_type2)\n",
    "\n",
    "# Calculate Pearson correlations for other features\n",
    "attack_rate_correlation, _ = compute_dict_correlation(ar1, ar2)\n",
    "ph_correlation, _ = compute_dict_correlation(average_pitch_heights1, average_pitch_heights2)\n",
    "mode_correlation, _ = compute_dict_correlation(modes1, modes2)\n",
    "\n",
    "# Print correlation results for various features\n",
    "print(\"Correlation of Attack Rates:\", round(attack_rate_correlation, 3))\n",
    "print(\"Correlation of Pitch Heights:\", round(ph_correlation, 3))\n",
    "print(\"Correlation of Modes:\", round(mode_correlation, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scriabin\n",
    "\n",
    "Stimuli:\n",
    "'/Users/Ben/Downloads/MAPLE Lab/Thesis_Project/Audio Files/Scriabin/scriabinLevy2015 - Stimuli'\n",
    "\n",
    "Full Tracks:\n",
    "'/Users/Ben/Downloads/MAPLE Lab/Thesis_Project/Audio Files/Scriabin/scriabinLevy2015 - Full Tracks'\n",
    "\n",
    "Shostakovich\n",
    "\n",
    "Stimuli:\n",
    "'/Users/Ben/Downloads/MAPLE Lab/Thesis_Project/Audio Files/Shostakovich/shostakovichBoyadjieva2009 - Stimuli'\n",
    "\n",
    "Full Tracks:\n",
    "'/Users/Ben/Downloads/MAPLE Lab/Thesis_Project/Audio Files/Shostakovich/shostakovichBoyadjieva2009 - Full Tracks'\n",
    "\n",
    "Kabalevsky\n",
    "\n",
    "Stimuli: '/Users/Ben/Downloads/MAPLE Lab/Thesis_Project/Audio Files/Kabalevksy/kabalevskyDossin2007 - Stimuli'\n",
    "\n",
    "Full Tracks: '/Users/Ben/Downloads/MAPLE Lab/Thesis_Project/Audio Files/Kabalevksy/kabalevskyDossin2007 - Full Tracks'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "ar1 = dict(sorted(ar1.items()))\n",
    "ar2 = dict(sorted(ar2.items()))\n",
    "\n",
    "# Combine dictionaries by keys\n",
    "combined_data = [[\"PieceID\", \"Stimuli\", \"Full Tracks\", \"Mode\"]]  # Add a header row\n",
    "for key in ar1.keys():\n",
    "    value1 = ar1.get(key, \"\")  # Get value from ar1 or default to empty string\n",
    "    value2 = ar2.get(key, \"\")  # Get value from ar2 or default to empty string\n",
    "    \n",
    "    # Determine the mode (Major or minor)\n",
    "    if \"M\" in key:\n",
    "        mode = \"Major\"\n",
    "    else:\n",
    "        mode = \"minor\"\n",
    "\n",
    "    combined_data.append([key, value1, value2, mode])\n",
    "\n",
    "# Write to CSV\n",
    "with open('ar_st_ka.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(combined_data)\n",
    "\n",
    "print(\"CSV file has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "average_pitch_heights1 = dict(sorted(average_pitch_heights1.items()))\n",
    "average_pitch_heights2 = dict(sorted(average_pitch_heights2.items()))\n",
    "\n",
    "# Combine dictionaries by keys\n",
    "combined_data = [[\"PieceID\", \"Stimuli\", \"Full Tracks\", \"Mode\"]]  # Add a header row\n",
    "for key in average_pitch_heights1.keys():\n",
    "    value1 = average_pitch_heights1.get(key, \"\")  # Get value from tempos1 or default to empty string\n",
    "    value2 = average_pitch_heights2.get(key, \"\")  # Get value from tempos2 or default to empty string\n",
    "    if \"M\" in key:\n",
    "        mode = \"Major\"\n",
    "    else:\n",
    "        mode = \"minor\"\n",
    "\n",
    "    combined_data.append([key, value1, value2, mode])\n",
    "\n",
    "# Write to CSV\n",
    "with open('ph_st_ka.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(combined_data)\n",
    "\n",
    "print(\"CSV file has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "modes1 = dict(sorted(modes1.items()))\n",
    "modes2 = dict(sorted(modes2.items()))\n",
    "\n",
    "# Combine dictionaries by keys\n",
    "combined_data = [[\"PieceID\", \"Stimuli\", \"Full Tracks\", \"Mode\"]]  # Add a header row\n",
    "for key in modes1.keys():\n",
    "    value1 = modes1.get(key, \"\")  # Get value from tempos1 or default to empty string\n",
    "    value2 = modes2.get(key, \"\")  # Get value from tempos2 or default to empty string\n",
    "    if \"M\" in key:\n",
    "        mode = \"Major\"\n",
    "    else:\n",
    "        mode = \"minor\"\n",
    "\n",
    "    combined_data.append([key, value1, value2, mode])\n",
    "\n",
    "# Write to CSV\n",
    "with open('mode_st_ka.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(combined_data)\n",
    "\n",
    "print(\"CSV file has been created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
